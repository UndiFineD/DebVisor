#!/usr/bin/env bash
###############################################################################
# DebVisor Enhanced CLI Wrapper - Ceph Management
#
# Advanced Ceph cluster management commands with:
# - Health diagnostics and recommendations
# - PG balancing analysis and recommendations
# - Automated OSD replacement with safety checks
# - Pool optimization (SSD/HDD/general workloads)
# - Performance analysis and bottleneck detection
###############################################################################

set -euo pipefail

# Color codes
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Helper functions
log_info() {
    echo -e "${BLUE}ℹ${NC} $*"
}

log_success() {
    echo -e "${GREEN}✓${NC} $*"
}

log_warning() {
    echo -e "${YELLOW}⚠${NC} $*"
}

log_error() {
    echo -e "${RED}✗${NC} $*"
}

###############################################################################
# Core Command Executor
###############################################################################

class_CephCommandExecutor() {
    # Execute Ceph commands safely
    execute_ceph_command() {
        local cmd="$1"
        ceph "${cmd[@]}" 2>&1 || {
            log_error "Command failed: ceph ${cmd[@]}"
            return 1
        }
    }

    # Get cluster status
    get_cluster_status() {
        ceph status --format json 2>/dev/null | python3 -m json.tool
    }

    # Get health warnings
    get_health_warnings() {
        ceph health detail 2>/dev/null
    }
}

###############################################################################
# Health & Diagnostics
###############################################################################

cmd_health_recommendations() {
    # Analyze cluster health and provide recommendations

    log_info "Analyzing cluster health..."

    local health_output
    health_output=$(ceph health detail 2>/dev/null || echo "")

    if [[ -z "$health_output" ]] || [[ "$health_output" == *"HEALTH_OK"* ]]; then
        log_success "Cluster is HEALTHY - no immediate actions needed"
        return 0
    fi

    log_warning "Cluster health issues detected:"
    echo "$health_output" | grep -E "^(HEALTH|PG|OSD|MON)" || true

    # Check for common issues
    echo ""
    log_info "Running diagnostic checks..."

    # Check for down OSDs
    local down_osds
    down_osds=$(ceph osd tree 2>/dev/null | grep -c " down " || echo "0")
    if [ "$down_osds" -gt 0 ]; then
        log_warning "$down_osds OSD(s) are DOWN"
        echo "  Recommendation: Investigate and restart failed OSDs"
        echo "  Command: ceph osd tree | grep down"
    fi

    # Check for full pools
    local full_pools
    full_pools=$(ceph df 2>/dev/null | grep -c "FULL" || echo "0")
    if [ "$full_pools" -gt 0 ]; then
        log_warning "$full_pools pool(s) are FULL"
        echo "  Recommendation: Expand pools or add OSDs"
        echo "  Command: ceph df detail"
    fi

    # Check PG status
    local stuck_pgs
    stuck_pgs=$(ceph pg stat 2>/dev/null | grep -o "[0-9]* stuck" | awk '{print $1}' || echo "0")
    if [ "$stuck_pgs" -gt 0 ]; then
        log_warning "$stuck_pgs PG(s) are STUCK"
        echo "  Recommendation: Investigate PG state"
        echo "  Command: ceph pg stat"
    fi

    log_success "Health analysis complete"
}

###############################################################################
# PG Balancing
###############################################################################

cmd_pg_balance() {
    # Analyze and recommend PG balancing

    log_info "Analyzing PG distribution..."

    local pg_stat
    pg_stat=$(ceph pg stat 2>/dev/null)

    echo "$pg_stat"
    echo ""

    # Check for unbalanced PGs
    local imbalanced=0
    while IFS= read -r line; do
        if [[ "$line" == *"pgs:"* ]]; then
            if echo "$line" | grep -q "unclean\|stale\|undersized"; then
                imbalanced=$((imbalanced + 1))
            fi
        fi
    done <<< "$pg_stat"

    if [ "$imbalanced" -gt 0 ]; then
        log_warning "Found $imbalanced unbalanced PG state(s)"
        echo ""
        echo "Recommendations:"
        echo "  1. Monitor further with: ceph pg stat --watch"
        echo "  2. Check OSD load with: ceph osd df"
        echo "  3. Adjust pg_num/pgp_num with caution"
    else
        log_success "PG distribution appears balanced"
    fi
}

###############################################################################
# OSD Management
###############################################################################

cmd_osd_status() {
    # Show OSD status dashboard

    log_info "OSD Status Dashboard:"
    echo ""

    ceph osd tree
}

cmd_osd_replace() {
    # Guided OSD replacement workflow

    local osd_id="$1"

    if [[ -z "$osd_id" ]]; then
        log_error "Usage: cephctl osd-replace <osd-id>"
        return 1
    fi

    log_info "Starting guided OSD replacement for OSD $osd_id"
    echo ""

    # Pre-flight checks
    log_info "Running pre-flight checks..."

    # Check cluster health
    local health
    health=$(ceph health 2>/dev/null | head -1)
    if [[ "$health" != "HEALTH_OK" ]]; then
        log_warning "Cluster health is not OK: $health"
        echo "  Proceed anyway? (yes/no)"
        read -r response
        if [[ "$response" != "yes" ]]; then
            log_error "Aborted"
            return 1
        fi
    fi

    # Check OSD exists
    if ! ceph osd tree 2>/dev/null | grep -q "osd\.$osd_id"; then
        log_error "OSD $osd_id not found"
        return 1
    fi

    log_success "Pre-flight checks passed"
    echo ""

    # Step 1: Mark OSD as out
    log_info "Step 1: Marking OSD $osd_id as OUT..."
    ceph osd out osd.$osd_id

    # Step 2: Wait for rebalancing
    log_info "Step 2: Waiting for data migration..."
    echo "  Monitor with: watch 'ceph -s'"
    sleep 2

    # Step 3: Stop OSD service
    log_info "Step 3: Stopping OSD $osd_id service..."
    systemctl stop ceph-osd@$osd_id.service || true

    # Step 4: Remove OSD
    log_info "Step 4: Removing OSD $osd_id from cluster..."
    ceph osd rm osd.$osd_id
    ceph auth del osd.$osd_id

    # Step 5: Purge OSD data
    log_info "Step 5: Purge OSD data (optional)"
    echo "  Manual command: ceph-volume lvm zap <device>"

    log_success "OSD $osd_id replacement workflow complete"
}

###############################################################################
# Pool Optimization
###############################################################################

cmd_pool_optimize() {
    # Pool parameter tuning based on workload

    local pool_name="$1"
    local workload="${2:-general}"

    if [[ -z "$pool_name" ]]; then
        log_error "Usage: cephctl pool-optimize <pool-name> [ssd|hdd|general]"
        return 1
    fi

    log_info "Optimizing pool '$pool_name' for $workload workload"

    # Get current pool stats
    local pool_info
    pool_info=$(ceph osd pool get "$pool_name" all 2>/dev/null)

    echo "$pool_info" | head -10
    echo ""

    case "$workload" in
        ssd)
            log_info "Recommendations for SSD workload:"
            echo "  - Increase cache_target_dirty_ratio (0.4 - 0.6)"
            echo "  - Increase cache_min_flush_age (0.5 - 1.0 seconds)"
            echo "  - Enable cache_target_full_ratio (0.8)"
            echo ""
            echo "  Apply with:"
            echo "    ceph osd pool set $pool_name cache_target_dirty_ratio 0.5"
            ;;
        hdd)
            log_info "Recommendations for HDD workload:"
            echo "  - Decrease cache_target_dirty_ratio (0.2 - 0.3)"
            echo "  - Increase cache_min_flush_age (2.0 - 5.0 seconds)"
            echo "  - Increase pg_num if fragmented"
            echo ""
            echo "  Apply with:"
            echo "    ceph osd pool set $pool_name cache_target_dirty_ratio 0.25"
            ;;
        general)
            log_info "Recommendations for general workload (balanced):"
            echo "  - cache_target_dirty_ratio: 0.4"
            echo "  - cache_min_flush_age: 1.0 seconds"
            echo "  - Balanced PG count (power of 2)"
            ;;
    esac
}

###############################################################################
# Performance Analysis
###############################################################################

cmd_perf_analyze() {
    # Performance diagnostics and bottleneck detection

    log_info "Collecting performance metrics..."

    # Get cluster performance stats
    local perf_stats
    perf_stats=$(ceph status --format json 2>/dev/null)

    # Parse and display metrics
    echo "$perf_stats" | python3 -c "
import json, sys
data = json.load(sys.stdin)
print(f\"Cluster Status: {data.get('health', {}).get('status', 'unknown')}\")
print(f\"Cluster Name: {data.get('cluster_name', 'unknown')}\")
print(f\"Monitors: {len(data.get('monmap', {}).get('mons', []))}\")
if 'pgmap' in data:
    pgmap = data['pgmap']
    print(f\"Active PGs: {pgmap.get('num_pgs', 0)}\")
    print(f\"Data Bytes: {pgmap.get('data_bytes', 0) / (1024**3):.1f} GB\")
" 2>/dev/null || echo "  (Could not parse metrics)"

    echo ""
    log_info "Performance bottleneck analysis:"

    # Check for slow requests
    local slow_ops
    slow_ops=$(ceph health detail 2>/dev/null | grep -i "slow\|stuck" || echo "none")
    if [[ "$slow_ops" != "none" ]]; then
        log_warning "Slow operations detected:"
        echo "$slow_ops" | sed 's/^/  /'
    else
        log_success "No slow operations detected"
    fi

    # OSD utilization
    log_info "OSD utilization check:"
    ceph osd df | tail -3
}

###############################################################################
# Main Command Router
###############################################################################

show_usage() {
    cat << EOF
DebVisor Enhanced Ceph CLI Wrapper

Usage: cephctl <command> [arguments]

Commands:
  health-recommendations    Analyze cluster health and provide recommendations
  pg-balance               Analyze and recommend PG balancing
  osd-status               Show OSD status dashboard
  osd-replace <id>         Guided OSD replacement workflow
  pool-optimize <name>     Pool parameter tuning
  perf-analyze             Performance diagnostics and bottleneck detection

Examples:
  cephctl health-recommendations
  cephctl osd-replace 3
  cephctl pool-optimize ceph-data ssd
  cephctl perf-analyze

For more information: https://docs.debvisor.io/cephctl
EOF
}

main() {
    if [[ $# -eq 0 ]]; then
        show_usage
        exit 1
    fi

    case "$1" in
        health-recommendations)
            cmd_health_recommendations
            ;;
        pg-balance)
            cmd_pg_balance
            ;;
        osd-status)
            cmd_osd_status
            ;;
        osd-replace)
            shift
            cmd_osd_replace "$@"
            ;;
        pool-optimize)
            shift
            cmd_pool_optimize "$@"
            ;;
        perf-analyze)
            cmd_perf_analyze
            ;;
        --help|-h|help)
            show_usage
            ;;
        *)
            log_error "Unknown command: $1"
            show_usage
            exit 1
            ;;
    esac
}

main "$@"
