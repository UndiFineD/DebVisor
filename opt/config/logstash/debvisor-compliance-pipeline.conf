input {
  kafka {
    bootstrap_servers => "kafka01:9092,kafka02:9092,kafka03:9092"
    topics => ["debvisor-compliance-logs"]
    group_id => "debvisor-logstash"
    codec => "json"
  }
}

filter {
  # Add metadata for compliance
  mutate {
    add_field => { "pipeline" => "debvisor-compliance" }
    add_field => { "ingested_at" => "%{@timestamp}" }
  }
}

output {
  # Elasticsearch for dashboards & search
  elasticsearch {
    hosts => ["http://es01:9200", "http://es02:9200"]
    index => "debvisor-compliance-%{+YYYY.MM.dd}"
    user => "elastic"
    password => "${ELASTIC_PASSWORD}"
    ssl => true
  }

  # S3 for immutable compliance archive
  s3 {
    access_key_id => "${AWS_ACCESS_KEY}"
    secret_access_key => "${AWS_SECRET_KEY}"
    region => "us-east-1"
    bucket => "debvisor-compliance-archive"
    prefix => "logs/%{+YYYY}/%{+MM}/%{+dd}/"
    canned_acl => "bucket-owner-full-control"
    codec => "json_lines"
    # Ensure append-only storage (object lock/WORM enabled at bucket level)
  }
}
